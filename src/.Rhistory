# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(length(shrink),50)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(length(shrink),5)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
browser()
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(length(shrink),5)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(length(shrink),5)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
browser()
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
count
ari_boots
ari_per_shrink
length(shrink)
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(0,nrow = length(shrink),ncol = 5)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
browser()
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
ari_per_shrink
aa
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1))
{
ari_per_shrink <- matrix(0,nrow = length(shrink),ncol = 5)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,5)
for(i in 1:5){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1),nboots = 50)
{
ari_per_shrink <- matrix(0,nrow = length(shrink),ncol = nboots)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,nboots)
for(i in 1:nboots){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = train.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.1))
aa
# boxviolin plot
a[,1]
# boxviolin plot
a[1,]
# boxviolin plot
aa[1,]
# boxviolin plot
gbm_results <- data.frame(first <- rep(0,50))
# boxviolin plot
gbm_results <- data.frame(first = rep(0,50))
gbm_results$first....rep.0..50.
gbm_results$first
gbm_results$first <- aa[1,]
gbm_results$first
boxplot(gbm_results$first)
# boxviolin plot
gbm_results <- data.frame(first = rep("0.05",50))
gbm_results$ari <- aa[1,]
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(first),
y = ari)) + geom_boxplot(aes(x = as.factor(first),
y = ari))
p
aa <- find_shrinkage(shrink = c(0.01,0.1,0.2))
aa
# boxviolin plot
gbm_results <- data.frame(first = rep("0.05",50*3))
cbind(aa[1,])
cbind(aa[1,],aa[2,])
cbind(aa[1,],aa[2,],aa[3,])
rbind(aa[1,],aa[2,],aa[3,])
c(aa[1,],aa[2,],aa[3,])
shrinkages <- c(rep("0.01",50),rep("0.1",50),rep("0.2",50))
aris <- c(aa[1,],aa[2,],aa[3,])
shrinkages
aris
# boxviolin plot
gbm_results <- data.frame(shrinkages,aris)
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris))
p
aa[3,]
aa <- find_shrinkage(shrink = c(0.01,0.1,0.2,0.5))
aris <- c(aa[1,],aa[2,],aa[3,],aa[4,])
# boxviolin plot
gbm_results <- data.frame(shrinkages,aris)
shrinkages
aa
aa
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1),nboots = 50)
{
ari_per_shrink <- matrix(0,nrow = length(shrink),ncol = nboots)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,nboots)
for(i in 1:nboots){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = test.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,true_train)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.01,0.1,0.2,0.5))
# custom function to check shrinkage parmaeter.
find_shrinkage <- function(shrink = c(0.1),nboots = 50)
{
ari_per_shrink <- matrix(0,nrow = length(shrink),ncol = nboots)
count = 1;
for(s_i in shrink) {
# go for 50 bootstraps
ari_boots <- rep(0,nboots)
for(i in 1:nboots){
# randomely stratify sample
pima <- rbind(Pima.tr,Pima.te)
pima[,-8] <- scale(pima[,-8])
# classes are not even so I am going to do bootstrap
# sampling to create my own training set
len_pima <- dim(pima)[1]
ind_train <- sample(1:len_pima, as.integer(len_pima*0.80))
train.n <- pima[ind_train,]
test.n  <- pima[-ind_train,]
# scaling some stuff
train.n[,-8] <- scale(train.n[,-8])
test.n[,-8] <- scale(test.n[,-8])
# keep number of trees constant
ntrees <- 311
f_diabetes <- formula(type ~ age + ped + bmi + skin + bp + glu + npreg )
train.n$type <- as.numeric(train.n$type == "Yes")
boost.pima=gbm(formula = f_diabetes,
data= train.n,
distribution="bernoulli",
n.trees=ntrees,
interaction.depth=2,
shrinkage = s_i,
n.minobsinnode = 10)
y_hat = predict(boost.pima, newdata = test.n,n.trees = ntrees,type=  "response")
pred_hat <- as.numeric(0.5 < y_hat)
true_train <- train.n$type
# calculate adjusted rand index.
adjust <- adjustedRandIndex(pred_hat,test.n$type)
ari_boots[i] <- adjust
} # end bootstraps
# put bootstraps into matrix
ari_per_shrink[count,] <- ari_boots
count <- count + 1
}  # end for loop
return(ari_per_shrink)
}
aa <- find_shrinkage(shrink = c(0.01,0.1,0.2,0.5))
shrinkages <- c(rep("0.01",50),rep("0.1",50),rep("0.2",50),rep("0.5",50))
aris <- c(aa[1,],aa[2,],aa[3,],aa[4,])
# boxviolin plot
gbm_results <- data.frame(shrinkages,aris)
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris))
p
aa <- find_shrinkage(shrink = c(0.001,0.01,0.1,0.2,0.5))
shrinkages <- c(rep("0.001",50),rep("0.01",50),rep("0.1",50),rep("0.2",50),rep("0.5",50))
aris <- c(aa[1,],aa[2,],aa[3,],aa[4,],aa[5,])
# boxviolin plot
gbm_results <- data.frame(shrinkages,aris)
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris))
p
aa <- find_shrinkage(shrink = c(0.005,0.01,0.1,0.2,0.5))
shrinkages <- c(rep("0.005",50),rep("0.01",50),rep("0.1",50),rep("0.2",50),rep("0.5",50))
aris <- c(aa[1,],aa[2,],aa[3,],aa[4,],aa[5,])
# boxviolin plot
gbm_results <- data.frame(shrinkages,aris)
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris))
p
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris)) +
labs(x = "Shrinkages")
p
p <- ggplot(gbm_results) + geom_violin(aes(x = as.factor(shrinkages),
y = aris)) + geom_boxplot(aes(x = as.factor(shrinkages),
y = aris)) +
labs(x = "shrinkage")
p
plot(boost.pima)
plot(sm.boost.pima)
sm.boost.pima
summary(boost.pima)
